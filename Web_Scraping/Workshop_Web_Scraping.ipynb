{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Josh-techie/AI-TPs/blob/master/Web_Scraping/Workshop_Web_Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><h1> <b>Atelier II : Data Collection </b></h1></center>\n",
        "<center><h3> Data Science</h3></center>\n",
        "<center><h3>14 Mars 2024</h3></center>\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "vBY1Vdsp00eN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise I:\n",
        "https://www.annuaire-gratuit.ma/ is a directory that contains over 189,000 addresses, prayer times, emergency pharmacies, train schedules, prayer times...\n",
        "In this exercise, we focus on emergency pharmacies in Moroccan cities.\n",
        "\n",
        "- Create a bot that collects emergency pharmacies in the cities:\n",
        "Agadir, Casablanca, Rabat, Fes, Tangier, Safi, Kenitra, Marrakech, Taza, Ouarzazate, Tiznit, Nador.\n",
        "- Store this information in a DataFrame (pandas).\n",
        "- Save the DataFrames in a csv file.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_A4kHWQQupmF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To use secret Key in the notebook, use the following**"
      ],
      "metadata": {
        "id": "n33cNRCWOKT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('OPENWEATHERAPI')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wrb8uQs2OPLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZjGVq1o2qHkw"
      },
      "outputs": [],
      "source": [
        "user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36\"\n",
        "cities = ['Agadir', 'Casablanca', 'Rabat', 'Fes', 'Tanger', 'Safi', 'Kenitra', 'Marrakech', 'Taza', 'Ouarzazate', 'Tiznit', 'Nador']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "898TI_lJXoFi",
        "outputId": "96ca90c8-1146-42b8-b406-a02c426080e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "HFyR6-ojAI1B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as BeautifulSoup"
      ],
      "metadata": {
        "id": "v2FJYXgxXxUG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "8vjGFDmaXzlp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "3hW_lGTjPB8E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cities we want to scrape:\n",
        "cities = [\"Agadir\", \"Casablanca\", \"Rabat\", \"Fes\"]\n",
        "\n",
        "# first start by creating a list of the attributes we wants\n",
        "\n",
        "pharmacy_names = []\n",
        "pharmacy_addresses = []\n",
        "pharmacy_telephones = []\n",
        "\n",
        "# then we loop through the cities and scrape the data\n",
        "\n",
        "for city in cities:\n",
        "    page_to_scrape = f\"https://www.annuaire-gratuit.ma/pharmacie-garde-{city}.html\"\n",
        "\n",
        "    # send the request to that particular url\n",
        "    response = requests.get(page_to_scrape)\n",
        "    # print(page_to_scrape)\n",
        "    # check the status code and handle errors\n",
        "    if response.status_code == 200:\n",
        "        print(\"Request was successful\")\n",
        "        # specify the parser html.parser\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "        # parse pharmacy names then append to the list\n",
        "        pharmcy_name = soup.find_all(\"h3\", itemprop=\"name\")\n",
        "        for ph_name in pharmcy_name:\n",
        "            # print(ph_name.text)\n",
        "            pharmacy_names.append(ph_name.text)\n",
        "\n",
        "        # parse pharmacy addresses then append to the list\n",
        "        pharmacy_addres = soup.find_all(\"p\", itemprop=\"streetAddress\")\n",
        "        for ph_add in pharmacy_addres:\n",
        "            # print(ph_add.text)\n",
        "            pharmacy_addresses.append(ph_add.text)\n",
        "\n",
        "        phoneNumbers = soup.find_all(style=\"font-weight: bold; color:#1e6dab\")\n",
        "        # print(phoneNumbers.text)\n",
        "\n",
        "        # parse pharmacy phone numbers then append to the list\n",
        "        for phoneNumber in phoneNumbers:\n",
        "            # print(phoneNumber.text)\n",
        "            pharmacy_telephones.append(phoneNumber.text)\n",
        "            # print(pharmacy_telephones)\n",
        "\n",
        "        # here we'll create the dataframe\n",
        "        data_pharmacies = pd.DataFrame(\n",
        "            {\n",
        "                \"Name\": pharmacy_names,\n",
        "                \"Address\": pharmacy_addresses,\n",
        "                \"Telephone\": pharmacy_telephones,\n",
        "            }\n",
        "        )\n",
        "        # pharmacy_data = pd.DataFrame(city)\n",
        "\n",
        "        # here I'll export the  data as csv\n",
        "        data_pharmacies.to_csv(f\"{city}.csv\", index=False)\n",
        "        # print(response.text)\n",
        "        pharmacy_names.__len__()\n",
        "        # clear the lists\n",
        "        pharmacy_names.clear()\n",
        "        pharmacy_addresses.clear()\n",
        "        pharmacy_telephones.clear()\n",
        "    else:\n",
        "        print(\"Request Failed, with status code\", response.status_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7hBEtcGOsAL",
        "outputId": "a9c0ad3b-84fa-48cd-b3f2-3148ddde0dbd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Request was successful\n",
            "Request was successful\n",
            "Request was successful\n",
            "Request was successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Print the dataframe so later I'll merge both don't worry you'll understand once you read the second exercice 🌟** erf fuck I'll have to scrape the city as well later 😥"
      ],
      "metadata": {
        "id": "gRRLhMthS5xu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_pharmacies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEsR8BxfTA8E",
        "outputId": "38df49f9-5015-4dbe-9265-060ff6fcaf62"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  Name                                            Address  \\\n",
            "0     Pharmacie Maalal  Pharmacie Maalal, n° 64 lot. hiba n°1 oued fes...   \n",
            "1      Pharmacie Driss  Pharmacie Driss, 2 lot. almssala, hay al mssal...   \n",
            "2  Pharmacie Ibn Nafis  Pharmacie Ibn Nafis, hay ain chkef dommaine ai...   \n",
            "3   Pharmacie Al Aziza  Pharmacie Al Aziza, numéro 1 lotissement al az...   \n",
            "4  Pharmacie El Otmani  Pharmacie El Otmani, 52 bd boufekran aouinate ...   \n",
            "5   Pharmacie Al Ahbab  Pharmacie Al Ahbab, 254 lot al fadila 3 route ...   \n",
            "\n",
            "   Telephone  \n",
            "0  053564...  \n",
            "1  053200...  \n",
            "2  061441...  \n",
            "3  053560...  \n",
            "4  053596...  \n",
            "5  053487...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise II:**\n",
        "\n",
        "OpenWeatherMap is an online service, owned by OpenWeather Ltd, that provides global weather data through an API, including current weather data, forecasts, immediate forecasts, and historical weather data for any geographical location.\n",
        "\n",
        "* Create a bot that collects the minimum temperature, maximum temperature, humidity, longitude, and latitude of the cities from Exercise I.\n",
        "* Store this information in a DataFrame (pandas).\n",
        "* Merge the DataFrame with the one you created in Exercise 1.\n",
        "* Save the DataFrames to a csv file.\n",
        "\n",
        "**You must first register to obtain a key in order to send requests to this API.**\n",
        "\n"
      ],
      "metadata": {
        "id": "ThmkrjmJxiEL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We will create a function to convert from Fahrenheit to Celsius since, we get data in Fahrenheit from the API**"
      ],
      "metadata": {
        "id": "_qJM8OX8ohkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert from Fahrenheit to Celsius\n",
        "def fahrenheit_to_celsius(fahrenheit):\n",
        "    celsius = (fahrenheit - 32) * 5/9\n",
        "    return celsius"
      ],
      "metadata": {
        "id": "ncfewX1-n9-l"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "temp_min = []\n",
        "temp_max = []\n",
        "humidity = []\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve the OpenWeatherMap API key from userdata\n",
        "OPENWEATHERAPI = userdata.get('OPENWEATHERAPI')\n",
        "\n",
        "# Ensure OPENWEATHERAPI is not None\n",
        "if OPENWEATHERAPI is None:\n",
        "    print(\"OpenWeatherMap API key not found. Please store your API key in userdata.\")\n",
        "else:\n",
        "  # create a  list where I will store all the data\n",
        "  cities_weather_data = []\n",
        "  for city in cities:\n",
        "    page = requests.get(f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={OPENWEATHERAPI}\")\n",
        "    d = json.loads(page.content)\n",
        "\n",
        "    # Extract min and max temperature and humidity from the JSON response\n",
        "    min_temp = fahrenheit_to_celsius(d[\"main\"][\"temp_min\"])\n",
        "    max_temp = fahrenheit_to_celsius(d[\"main\"][\"temp_max\"])\n",
        "    humidity = d[\"main\"][\"humidity\"]\n",
        "\n",
        "\n",
        "    # append each scraped data for each iteration and append it to the list of dic\n",
        "    cities_weather_data.append({\n",
        "        \"City\": city,\n",
        "        \"Min Temperature (C⁰)\": min_temp,\n",
        "        \"Max Temperature (C⁰)\": max_temp,\n",
        "        \"Humidity\": humidity,\n",
        "    })\n",
        "\n",
        "    # Print the weather data for the city\n",
        "    print(f\"The weather in {city} is: Min Temp: {min_temp}, Max Temp: {max_temp}, Humidity: {humidity} \")"
      ],
      "metadata": {
        "id": "mSvrWRK_zdTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6e581df-f8ef-469c-9fec-d55a6bf7c0c8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weather in Agadir is: Min Temp: 143.55555555555554, Max Temp: 143.55555555555554, Humidity: 85 \n",
            "The weather in Casablanca is: Min Temp: 142.86666666666667, Max Temp: 144.5666666666667, Humidity: 59 \n",
            "The weather in Rabat is: Min Temp: 140.10555555555555, Max Temp: 142.6277777777778, Humidity: 93 \n",
            "The weather in Fes is: Min Temp: 142.38333333333333, Max Temp: 142.38333333333333, Humidity: 67 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Store this information in a DataFrame (pandas)**\n",
        "\n",
        "> Create a DataFrame from the list of dictionaries ( Cities_weather_data )\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uuts3-aTrGAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame from the list of dictionaries\n",
        "cities_weather_df = pd.DataFrame(cities_weather_data)\n",
        "print(cities_weather_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBehWWVrrG4P",
        "outputId": "0b7047cd-b9b2-4c83-d30c-7db5c411f027"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         City  Min Temperature (C⁰)  Max Temperature (C⁰)  Humidity\n",
            "0      Agadir            143.555556            143.555556        85\n",
            "1  Casablanca            142.866667            144.566667        59\n",
            "2       Rabat            140.105556            142.627778        93\n",
            "3         Fes            142.383333            142.383333        67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's now read the csv we created previouslty for each city ◀**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> For Agadir 💪\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YZH9DmjbTwoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agadir = pd.read_csv('Agadir.csv')\n",
        "\n",
        "agadir_merged = pd.merge(agadir.assign(key=1), cities_weather_df[cities_weather_df['City'] == 'Agadir'].assign(key=1), on='key', how='left').drop('key', axis=1)\n",
        "\n",
        "agadir_merged.to_csv('Agadir_final.csv', index=False)"
      ],
      "metadata": {
        "id": "BJtX0JLiUAjs"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Same for the other cities 🎈**\n",
        "> Otherwise use a for loop"
      ],
      "metadata": {
        "id": "qnVEqx7mWJ7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Casablanca = pd.read_csv('Casablanca.csv')\n",
        "\n",
        "Casablanca_merged = pd.merge(agadir.assign(key=1), cities_weather_df[cities_weather_df['City'] == 'Casablanca'].assign(key=1), on='key', how='left').drop('key', axis=1)\n",
        "\n",
        "Casablanca_merged.to_csv('Casablanca_final.csv', index=False)\n",
        "\n",
        "# fes\n",
        "\n"
      ],
      "metadata": {
        "id": "UWfgLtkcWbIc"
      },
      "execution_count": 47,
      "outputs": []
    }
  ]
}